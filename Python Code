#####################
## Import Library ##
#####################
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pandas_profiling
import seaborn as sns; sns.set()
import math
from math import sqrt

# estimators
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn import linear_model


# model metrics
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler


# cross validation
from sklearn.model_selection import train_test_split

import warnings
def fxn():
    warnings.warn("deprecated", DeprecationWarning)
with warnings.catch_warnings():
    warnings.simplefilter("ignore")
    fxn()
    
%matplotlib inline

#################
## Import Data ##
#################

# locate data
file = 'SeoulBikeData.csv'

# load data
data = pd.read_csv(file,parse_dates=['Date'])

##########################
## EDA & Pre-Processing ##
##########################

# number of rows and columns 
data.shape
# (8760, 15)

# Remove duplicate data -- no duplicates
data = data.drop_duplicates()

# verify number of rows after duplicates dropped - confirmed
data.shape
# (8760, 15)

# preview first 5 rows 
data.head()

# all column headers 
data.columns
#Index(['Date', 'Day', 'Rented_Bike_Count', 'Hour', 'Temperature(∞C)',
#       'Humidity(%)', 'Wind speed (m/s)', 'Visibility (10m)',
#       'Dew point temperature(∞C)', 'Solar Radiation (MJ/m2)', 'Rainfall(mm)',
#       'Snowfall (cm)', 'Seasons', 'Holiday', 'Functioning Day'],
#      dtype='object')

# basic information on all columns (data type and null)
data.info()
# #   Column                     Non-Null Count  Dtype  
#---  ------                     --------------  -----  
# 0   Date                       8760 non-null   object 
# 1   Day                        8760 non-null   object 
# 2   Rented_Bike_Count          8760 non-null   int64  
# 3   Hour                       8760 non-null   int64  
# 4   Temperature(∞C)            8760 non-null   int64  
# 5   Humidity(%)                8760 non-null   int64  
# 6   Wind speed (m/s)           8760 non-null   float64
# 7   Visibility (10m)           8760 non-null   int64  
# 8   Dew point temperature(∞C)  8760 non-null   float64
# 9   Solar Radiation (MJ/m2)    8760 non-null   float64
# 10  Rainfall(mm)               8760 non-null   float64
# 11  Snowfall (cm)              8760 non-null   float64
# 12  Seasons                    8760 non-null   object 
# 13  Holiday                    8760 non-null   object 
# 14  Functioning Day            8760 non-null   object 

# basic statistics on numeric columns
data.describe()

# Rename columns 
data = data.rename(columns={'Temperature(∞C)': 'Temp', 'Dew point temperature(∞C)': 'dew_pt_temp'})

# shows what type the data was read in as
data.dtypes
# Date                        object
# Day                         object
# Rented_Bike_Count            int64
# Hour                         int64
# Temp                         int64
# Humidity(%)                  int64
# Wind speed (m/s)           float64
# Visibility (10m)             int64
# dew_pt_temp                float64
# Solar Radiation (MJ/m2)    float64
# Rainfall(mm)               float64
# Snowfall (cm)              float64
# Seasons                     object
# Holiday                     object
# Functioning Day             object

# Create translation tables for day, season, holiday, funcationing day

data['Seasons']=np.where(data['Seasons'] == 'Spring', 1, data['Seasons'])
data['Seasons']=np.where(data['Seasons'] == 'Summer', 2, data['Seasons'])
data['Seasons']=np.where(data['Seasons'] == 'Autumn', 3, data['Seasons'])
data['Seasons']=np.where(data['Seasons'] == 'Winter', 4, data['Seasons'])
data['Holiday']=np.where(data['Holiday'] == 'No Holiday', 0, data['Holiday'])
data['Holiday']=np.where(data['Holiday'] == 'Holiday', 1, data['Holiday'])
data['Functioning Day']=np.where(data['Functioning Day'] == 'No', 0, data['Functioning Day'])
data['Functioning Day']=np.where(data['Functioning Day'] == 'Yes', 1, data['Functioning Day'])
data['Day']=np.where(data['Day'] == 'Monday', 1, data['Day'])
data['Day']=np.where(data['Day'] == 'Tuesday', 2, data['Day'])
data['Day']=np.where(data['Day'] == 'Wednesday', 3, data['Day'])
data['Day']=np.where(data['Day'] == 'Thursday', 4, data['Day'])
data['Day']=np.where(data['Day'] == 'Friday', 5, data['Day'])
data['Day']=np.where(data['Day'] == 'Saturday', 6, data['Day'])
data['Day']=np.where(data['Day'] == 'Sunday', 7, data['Day'])

# While I like to control what the translation output is, an easier method is ... 'Get dummies'
        # data = pd.get_dummies(df, drop_first=True,
                   # columns=['Seasons', 'Holiday', 'Functioning Day'])
# parse out month            
data['Month'] = data['Date'].apply(lambda x: x.month)
data.drop(columns=["Date"], inplace=False)

# Update data types to numeric. 
cols = ['Day','Seasons','Holiday','Functioning Day']
data[cols] = data[cols].apply(pd.to_numeric, errors='coerce', axis=1) 

# Verify updated data types
data.info()
# #   Column                   Non-Null Count  Dtype  
#---  ------                   --------------  -----  
# 0   Date                     8760 non-null   object 
# 1   Day                      8760 non-null   int64  
# 2   Rented_Bike_Count        8760 non-null   int64  
# 3   Hour                     8760 non-null   int64  
# 4   Temp                     8760 non-null   int64  
# 5   Humidity(%)              8760 non-null   int64  
# 6   Wind speed (m/s)         8760 non-null   float64
# 7   Visibility (10m)         8760 non-null   int64  
# 8   dew_pt_temp              8760 non-null   float64
# 9   Solar Radiation (MJ/m2)  8760 non-null   float64
# 10  Rainfall(mm)             8760 non-null   float64
# 11  Snowfall (cm)            8760 non-null   float64
# 12  Seasons                  8760 non-null   int64  
# 13  Holiday                  8760 non-null   int64  
# 14  Functioning Day          8760 non-null   int64  
# 15  bike_count               8760 non-null   int64  

# shows which columns have null values
data.isnull().any()
# Date                       False
# Day                        False
# Rented_Bike_Count          False
# Hour                       False
# Temp                       False
# Humidity(%)                False
# Wind speed (m/s)           False
# Visibility (10m)           False
# dew_pt_temp                False
# Solar Radiation (MJ/m2)    False
# Rainfall(mm)               False
# Snowfall (cm)              False
# Seasons                    False
# Holiday                    False
# Functioning Day            False
# bike_count                 False

# plot histograms for all numeric columns 
data.hist() 

# Pandas profiling report
pandas_profiling.ProfileReport(data)

# Calculate covariance
covMat = data.cov()
print(covMat)

# Correlation coefficient matrix
corrMat = data.corr()
print(corrMat)
#                        Rented_Bike_Count 
# Day                            -0.029357 
# Rented_Bike_Count               1.000000 
# Hour                            0.410257  -- ** 
# Temp                            0.538713  -- ** 
# Humidity(%)                    -0.199780 
# Wind speed (m/s)                0.121108 
# Visibility (10m)                0.199280 
# dew_pt_temp                     0.379788 
# Solar Radiation (MJ/m2)         0.261837 
# Rainfall(mm)                   -0.123074 
# Snowfall (cm)                  -0.141804 
# Seasons                        -0.297095 
# Holiday                        -0.072338 
# Functioning Day                 0.203943 

# Histogram of rented bike count 
data.hist('Rented_Bike_Count')

# Graph = Rented Bike Count by Season 
fig = sns.FacetGrid(data, hue='Seasons', aspect=4)
fig.map(sns.kdeplot, 'Rented_Bike_Count', shade=True)
fig.add_legend()
## In winter, they typically have less than 500 people biking
## In Summer, they typically have more than 500 bikers

# Temperature Range by Season
sns.relplot('Seasons','Temp',data=data)
## Spring & Fall have comparable temp (-5 to 30)
## Summer is the hottest (15 to 40)
## Winter is the coldest (-18 to 10)

# Humidity by Season
sns.relplot('Seasons','Humidity(%)',data=data)
## All about the same. 

# Rainfall & Humidity 
sns.relplot('Rainfall(mm)','Humidity(%)', data=data)
## When it rains, it's very humid; however, it can be 100% humid with no rain.

# Snowfall & Humidity
sns.relplot('Snowfall (cm)','Humidity(%)', data=data)
## Snowfall = higher humdity

# Frequency & amount of snowfall by season
sns.relplot('Seasons','Snowfall (cm)',data=data)
sns.catplot('Seasons', 'Snowfall (cm)',data=data)
## It doesn't snow in Spring nor Summer. 
## It snowed 25 days in Winter and 3 days in Fall. Interestingly, Fall had the highest single day amount of snow with 8.8cm. 

# Scatter plot bikes rented by temperature. 
sns.relplot('Temp','Rented_Bike_Count',data=data)
## When it's colder than -10 degrees, less than 500 bikes are rented
## There is a positive correlation between the temperatre rising and the number of bikes rented increasing. 

# Scatter plot of bikes rented by season 
sns.relplot('Seasons','Rented_Bike_Count',data=data)
## Winter has a considerably less rentals than the other seasons. 

# Bike rented by hour & season 
sns.catplot('Hour','Rented_Bike_Count' , hue='Seasons', data=data)
## Peaks at 7, 8, 18, 19 (possibly traveling to and from work). 

## From the graph above we can see there are peaks around 7,8,18,19 (possibly commuting hours). 
## create a new data point for weekend vs weekday. 
booleans = []
for weekday in data.Day:
        if weekday <= 5:
            booleans.append(True)
        else:
            booleans.append(False)
            
## This can also be written more simply like this: 
        ## data[data.Day <= 5]
    ## or
        ## weekday = data.Day <=5

# Boolean head - confirm boolean is working
booleans[0:5]
## [True, True, True, True, True]

# confirm length of boolean matches length of dataset. 
len(booleans)
## 8760

# Convert booleans list to panda series 
weekday = pd.Series(booleans)

# Add weekday indicator to dataset 
data['weekday'] = weekday 

# Confirm 'weekday' has been added
data.head()

## Bike rented by hour & weekday vs weekend
sns.catplot('Hour','Rented_Bike_Count' , hue='weekday', data=data)
## Based on the graph, the peak rentals hours (7,8,18,19) are typically on weekdays.

# Histogram (frequency) of temperature data
data.hist('Temp') 

# Scatter plot of biked rented based on temperature. 
sns.relplot('Temp','Rented_Bike_Count',data=data)
## Most bikes rented between 20 - 30 degrees. 

# Scatter plot of bikes rented by humdity. 
sns.relplot('Humidity(%)','Rented_Bike_Count',data=data)
## This presented a bell curve where lots of bikes were rented when humidity was between 40 - 60

# Scatter plot of rainfall vs. bikes rented. 
sns.relplot('Rainfall(mm)','Rented_Bike_Count',data=data)
## The more it rains the less bikes are rented. 

# Scatter plot of snowfall vs. bikes rented. 
sns.relplot('Snowfall (cm)','Rented_Bike_Count',data=data)
## The more it snows the less bikes are rented. 

# Scatter plot of visibility vs. bikes rented. 
sns.relplot('Visibility (10m)','Rented_Bike_Count',data=data)
## When there is less visibility bikes are rented less frequently. 

#########################
## Business Question 1 ##
#########################
# Is there a day of the week when bikes are rented more than others?

# Mean of bikes rented sorted by day 
data.groupby('Day')['Rented_Bike_Count'].mean()
# 1 Monday    730.563301 -- 3
# 2 Tuesday   687.977564 -- 6
# 3 Wednesday 740.349359 -- 2
# 4 Thursday  690.704327 -- 5
# 5 Friday    747.117925 -- 1 ** MOST
# 6 Saturday  709.528846 -- 4
# 7 Sunday    625.155449 -- 7 ** Least

# Sum of bikes rented sorted by day 
data.groupby('Day')['Rented_Bike_Count'].sum()
# 1 Monday    911743
# 2 Tuesday   858596
# 3 Wednesday 923956
# 4 Thursday  861999
# 5 Friday    950334
# 6 Saturday  885492
# 7 Sunday    780194

# Scatter plot of rented bikes by day or week 
sns.catplot('Day','Rented_Bike_Count', data=data)

## Most bikes are rented on Friday and least on Sunday 

#########################
## Business Question 2 ##
#########################
#Is there a season when bikes are rented more than others?

# Mean of bikes rented sorted by Season  
data.groupby('Seasons')['Rented_Bike_Count'].mean()
## 1 - spring -  730.031250 (26%)
## 2 - summer - 1034.073370 (37%)
## 3 - autumn -  819.597985 (29%)
## 4 - winter -  225.541204 (8%)

# Sum of bikes rented sorted by season
data.groupby('Seasons')['Rented_Bike_Count'].sum()
#1 - spring -  1,611,909
#2 - summer -  2,283,234
#3 - autumn -  1,790,002
#4 - winter -  487,169

# Sum of bikes rented sorted by day 
sns.catplot('Seasons','Rented_Bike_Count', data=data)

## Most bikes are rented in Summer and least in Winter 

#########################
## Business Question 3 ##
#########################
#Is there an hour when bikes are rented the most?

# Mean of bikes rented sorted by hour  
data.groupby('Hour')['Rented_Bike_Count'].mean()
## 0  -   541.460274
## 1  -   426.183562
## 2  -   301.630137
## 3  -   203.331507
## 4  -   132.591781 ** least
## 5  -   139.082192
## 6  -   287.564384
## 7  -   606.005479
## 8  -  1015.701370
## 9  -   645.983562
## 10 -   527.821918
## 11 -   600.852055
## 12 -   699.441096
## 13 -   733.246575
## 14 -   758.824658
## 15 -   829.186301
## 16 -   930.621918
## 17 -  1138.509589
## 18 -  1502.926027 ** most
## 19 -  1195.147945
## 20 -  1068.964384
## 21 -  1031.449315
## 22 -   922.797260
## 23 -   671.126027

# Sum of bikes rented sorted by hour
data.groupby('Hour')['Rented_Bike_Count'].sum()
## 0  -  197,633
## 1  -  155,557
## 2  -  110,095
## 3  -   74,216
## 4  -   48,396
## 5  -   50,765
## 6  -  104,961
## 7  -  221,192
## 8  -  370,731
## 9  -  235,784
## 10 -  192,655
## 11 -  219,311
## 12 -  255,296
## 13 -  267,635
## 14 -  276,971
## 15 -  302,653
## 16 -  339,677
## 17 -  415,556
## 18 -  548,568
## 19 -  436,229
## 20 -  390,172
## 21 -  376,479
## 22 -  336,821
## 23 -  244,961

# Scatter plot of bikes rented by hour. 
sns.catplot('Hour', 'Rented_Bike_Count', data=data)

## Peak hours (more than 2,500 rented) are 8, 14 - 22 Least hours (less than 1,000 rented) are 2 - 6

#########################
## Business Question 4 ##
#########################
# Is there a temperature when the most bikes are rented? 

# Histogram of temperature
data.hist('Temp')

# Scatter plot of bikes rented by temp. 
sns.relplot('Temp','Rented_Bike_Count',data=data)

# Scatter plot of bikes rented by temp & season 
sns.relplot('Temp','Rented_Bike_Count', hue='Seasons', data=data)

# Scatter plot of bikes rented by temp & hour 
sns.relplot('Temp','Rented_Bike_Count', hue='Hour', data=data)

# Create bins for hourly temp 
hourly_temp = ['1','2','3','4','5','6','7','8','9','10','11','12']
cut_bins1 = [-18, -15, -10, -5, 0, 5, 10, 15, 20, 25, 30, 35, 40]
data['hourly_temp'] = pd.cut(data['Temp'], bins=cut_bins1, labels=hourly_temp)

# Update data types to numeric. 
cols = ['hourly_temp']
data[cols] = data[cols].apply(pd.to_numeric, errors='coerce', axis=1) 

# Histogram of hourly temperature (binned) 
data.hist('hourly_temp')

# Mean of bikes rented sorted by hourly temp
data.groupby('hourly_temp')['Rented_Bike_Count'].mean()
##	1  ~ -18 to -15 --    104.652174  -- Lowest Rental Rate & Coldest Temp
##	2  ~ -14 to -10 --    150.741758   
##	3  ~  -9 to -5  --    177.180498   	   
##	4  ~  -4 to 0   --    237.132898     
##	5  ~   1 to 5   --    359.300546   
##	6  ~   6 to 10  --    547.994393   
##	7  ~  11 to 15  --    709.345437   
##	8  ~  16 to 20  --    869.956456   
##	9  ~  21 to 25  --  1,105.448698  
##	10 ~  26 to 30  --  1,216.847973  -- Highest Rental Rate 
##	11 ~  31 to 35  --  1,106.162088           
##  12 ~  36 to 39  --    865.181818  -- Hottest Temp

# Sum of bikes rented sorted by hour
data.groupby('hourly_temp')['Rented_Bike_Count'].sum()
##	1  ~ -18 to -15 --      4,814  -- Lowest Rental Rate & Coldest Temp
##	2  ~ -14 to -10 --     27,435   
##	3  ~  -9 to -5  --     85,401   	   
##	4  ~  -4 to 0   --    217,688     
##	5  ~   1 to 5   --    394,512   
##	6  ~   6 to 10  --    586,354   
##	7  ~  11 to 15  --    722,823   
##	8  ~  16 to 20  --  1,158,782   
##	9  ~  21 to 25  --  1,443,716  -- Highest Rental Rate
##	10 ~  26 to 30  --  1,080,561   
##	11 ~  31 to 35  --    402,643           
##  12 ~  36 to 39  --     47,585  -- Hottest Temp

## The temperature with the most rented bikes is 21 to 25 degrees. 
## The hottest (36 - 40) and coldest

##############
## Model 1 ##
##############
# Can we predict how many bikes will be rented in the future?

# define features - for the first model we will use all features. 
features = ['Day','Hour', 'Temp', 'Humidity(%)',
       'Wind speed (m/s)', 'Visibility (10m)', 'dew_pt_temp',
       'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)', 'Seasons',
       'Holiday', 'Functioning Day','Month']
X = data[features].copy()

# define dependent variable
y = data['Rented_Bike_Count']

# Configure Algorithms
algosClass = []
algosClass.append(('Random Forest Regressor',RandomForestRegressor()))
algosClass.append(('Linear Regression',LinearRegression()))
algosClass.append(('Support Vector Regression',SVR()))

# Regression
results = []
names = []
for name, model in algosClass:
    result = cross_val_score(model, X,y, cv=10, scoring='r2')
    names.append(name)
    results.append(result)
    
# print r2 results to determine best algorithm
for i in range(len(names)):
    print(names[i],results[i].mean())
## Random Forest Regressor 0.7408518326093902 -- ** 
## Linear Regression -0.5803263080117197
## Support Vector Regression -2.226352890414682

# create the necessary training and testing data (75/25)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 123)
  
#Modeling (Regression)
algo = RandomForestRegressor()
model = algo.fit(X_train,y_train)

# Print CV score
print(cross_val_score(model, X, y, cv=10))
## [-1.36954942  0.58864123  0.73418183  0.72964755  0.8551581   0.85801288  0.8156663   0.86126261  0.87205903  0.70233781]
## Based on these results, let's reduce cv to 5

# Train Set Predictions
predictions_train = model.predict(X_train)
predRsquared = r2_score(y_train,predictions_train)
rmse = sqrt(mean_squared_error(y_train, predictions_train))
print('R Squared: %.3f' % predRsquared)
print('RMSE: %.3f' % rmse)
## R Squared: 0.990
## RMSE: 63.626

# Test Set Predictions
predictions_test = model.predict(X_test)
predRsquared = r2_score(y_test,predictions_test)
rmse = sqrt(mean_squared_error(y_test, predictions_test))
print('R Squared: %.3f' % predRsquared)
print('RMSE: %.3f' % rmse)
## R Squared: 0.932
## RMSE: 165.997

print(predictions)
## [ 189.42  750.5  2133.18 ... 1775.25  399.85 1295.93]

# Variable Importance
tmp = pd.DataFrame({'Feature': X, 'Feature importance': algo.feature_importances_})
tmp = tmp.sort_values(by='Feature importance',ascending=False)
plt.figure(figsize = (7,4))
plt.title('Features importance',fontsize=14)
s = sns.barplot(x='Feature',y='Feature importance',data=tmp)
s.set_xticklabels(s.get_xticklabels(),rotation=90)
plt.show()
## Top 2 important features = Temp & Hour

# Predictions vs. Ground Truth scatter plot
rng = np.random.RandomState(0)
colors = rng.rand(2190)
plt.scatter(predictions_test, y_test, c=colors ,alpha = 1)
plt.xlabel('Ground Truth')
plt.ylabel('Predictions')
plt.show();

# Linear Regression
lr = LinearRegression()
lr.fit(X_train, y_train)

# Look at predictions on training and validation set
y_train_pred = lr.predict(X_train)
y_test_pred = lr.predict(X_test)

# Plot predictions
plt.scatter(y_train_pred, y_train, c = "blue", marker = "s", label = "Training data")
plt.scatter(y_test_pred, y_test, c = "lightgreen", marker = "s", label = "Validation data")
plt.title("Linear regression")
plt.xlabel("Predicted values")
plt.ylabel("Real values")
plt.show()

##############
## Model 2 ##
##############
# We know temp is a significant feature - let's try to bin temperatures and see if R2 increases. 

#define features
features = ['Day','Month','Hour', 'hourly_temp', 'Humidity(%)',
       'Wind speed (m/s)', 'Visibility (10m)', 'dew_pt_temp',
       'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)',
       'Holiday', 'Functioning Day']
X = data[features].copy()

# define dependent variable
y = data['Rented_Bike_Count']

# Configure Algorithms
algosClass = []
algosClass.append(('Random Forest Regressor',RandomForestRegressor()))
algosClass.append(('Linear Regression',LinearRegression()))
algosClass.append(('Support Vector Regression',SVR()))

# Regression
results = []
names = []
for name, model in algosClass:
    result = cross_val_score(model, X,y, cv=10, scoring='r2')
    names.append(name)
    results.append(result)
    
# print r2 results to determine best algorithm
for i in range(len(names)):
    print(names[i],results[i].mean())
## Random Forest Regressor 0.10691011805543034 -- ** 
## Linear Regression -0.8305023473710389
## Support Vector Regression -2.23233433155258

# Print CV score
print(cross_val_score(model, X, y, cv=10))
## [-5.79273625  0.37588019  0.73890692  0.71397409  0.8458479   0.84804388  0.78264051  0.85591533  0.86249041  0.61741528]
## Based on these results, let's reduce cv to 5

# Train Set Predictions
predictions_train = model.predict(X_train)
predRsquared = r2_score(y_train,predictions_train)
rmse = sqrt(mean_squared_error(y_train, predictions_train))
print('R Squared: %.3f' % predRsquared)
print('RMSE: %.3f' % rmse)
## R Squared: 0.990
## RMSE: 65.208

# Test Set Predictions
predictions_test = model.predict(X_test)
predRsquared = r2_score(y_test,predictions_test)
rmse = sqrt(mean_squared_error(y_test, predictions_test))
print('R Squared: %.3f' % predRsquared)
print('RMSE: %.3f' % rmse)
## R Squared: 0.931
## RMSE: 166.985

print(predictions_test)
[ 192.45  787.87 2118.37 ... 1768.56  386.93 1364.56]

# Variable Importance
tmp = pd.DataFrame({'Feature': X, 'Feature importance': algo.feature_importances_})
tmp = tmp.sort_values(by='Feature importance',ascending=False)
plt.figure(figsize = (7,4))
plt.title('Features importance',fontsize=14)
s = sns.barplot(x='Feature',y='Feature importance',data=tmp)
s.set_xticklabels(s.get_xticklabels(),rotation=90)
plt.show()
## Top 2 important features = Hourly_Temp & Hour

# Predictions vs. Ground Truth scatter plot
rng = np.random.RandomState(0)
colors = rng.rand(2190)
plt.scatter(predictions_test, y_test, c=colors ,alpha = 1)
plt.xlabel('Ground Truth')
plt.ylabel('Predictions')
plt.show();

